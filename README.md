
# Spatio-Temporal Interpolation Comparison

This repository contains a Python script (`interp_brdata.py`) that compares three interpolation methods—**Random Forest Regression**, **Linear Interpolation**, and **Cubic Spline Interpolation**—for reconstructing a global spatio-temporal dataset. The code processes time-series data on a latitude-longitude grid, interpolates missing time steps, and visualizes the results using Hammer projections with Basemap.

## Overview

The script loads a series of 2D spatial data files (e.g., `br_surf12x_0001.dat` to `br_surf12x_2000.dat`), representing magnetic field at the CMB over time on a global grid. The data is generated by post-processing state files generated by the Leeds Dynamo Code. It then:
1. Samples the data at regular intervals.
2. Applies three interpolation techniques to reconstruct the full time series.
3. Evaluates the accuracy of each method using Mean Squared Error (MSE) and Root Mean Squared Error (RMSE).
4. Visualizes the original and interpolated fields at selected time steps.

### Interpolation Methods
- **Random Forest Regression**: A machine learning approach using spatial (lat, lon) and temporal (time) features, with Gaussian smoothing for noise reduction.
- **Linear Interpolation**: A simple linear fit between sampled points along the time axis.
- **Cubic Spline Interpolation**: A smooth polynomial fit between sampled points.

### Purpose
This tool is designed to assess the effectiveness of different interpolation techniques for reconstructing dense spatio-temporal datasets from sparse samples. This is currently meant for magnetic field data. But the concept can be extended to other geospatial data.

## Features

- **Data Loading**: Reads Fortran-ordered `.dat` files and reshapes them into a 3D time-series array.
- **Grid Setup**: Uses a latitude-longitude grid with customizable resolution (default: 216 x 264).
- **Interpolation**: Implements three distinct methods with quantitative error metrics (MSE, RMSE).
- **Visualization**: Plots original and interpolated fields on a Hammer projection using Basemap.
-

## Requirements

- Python 3.x
- NumPy
- Matplotlib
- Basemap (`mpl_toolkits.basemap`)
- Scikit-learn
- SciPy

Install dependencies with:
```bash
pip install numpy matplotlib basemap sklearn scipy
```
Note: Basemap installation might require additional steps depending on your system (e.g., `conda install basemap` or building from source).

## Usage

1. **Clone the Repository**:
   ```bash
   git clone <repository-url>
   cd <repository-name>
   ```

2. **Prepare Data**:
   - Place input files (`br_surf12x_0001.dat` to `br_surf12x_2000.dat`) in the working directory.
   - Each file should contain a flattened 2D array (e.g., 216 x 264 values) in Fortran order.

3. **Run the Script**:
   ```bash
   python interp_brdata.py
   ```
   - The script processes 2000 time steps by default, sampling every 200 steps for interpolation.
   - Adjust `n_time_steps` and `sample_interval` in the code to match your data or experiment.

4. **Output**:
   - Console: Global and per-time-step MSE/RMSE for each method.
   - Plots: Four rows (Original, RF, Linear, Cubic) showing fields at three time steps on Hammer projections.

## Example Output

For a 2000-step dataset with a 216 x 264 grid:
- **Metrics**: Printed global and average RMSE values, e.g.:
  ```
  Random Forest - Global MSE: 0.1234, RMSE: 0.3513, Average RMSE: 0.3456
  Linear Interpolation - Global MSE: 0.1456, RMSE: 0.3816, Average RMSE: 0.3789
  Cubic Spline Interpolation - Global MSE: 0.1345, RMSE: 0.3667, Average RMSE: 0.3632
  ```
- **Plots**: Visual comparison of original vs. interpolated fields at t=100, t=1000, t=1700.

## Customization

- **Grid Size**: Modify `Nt` and `Np` for different resolutions.
- **Sample Interval**: Change `sample_interval` to adjust sparsity (default: 200).
- **RF Parameters**: Tune `n_estimators`, `max_depth`, etc., in `RandomForestRegressor`.
- **Time Steps**: Adjust `n_time_steps` to match your dataset.
- **Plot Times**: Edit `time_indices_to_plot` for different visualization points.

## Performance Notes

- **Threading**: Sets `OPENBLAS_NUM_THREADS` and `MKL_NUM_THREADS` to 4 to balance performance and resource use.
- **Random Forest**: Uses `n_jobs=-1` for parallel training across all available CPU cores.

## Limitations

- Assumes a specific data format (`Nt x Np` in Fortran order).
 

## Future Improvements

- Include additional interpolation methods (e.g., Neural Networks).
- Transition to Cartopy for modern mapping support.
- Optimize memory usage for larger datasets.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Acknowledgments

Built with contributions from NumPy, Scikit-learn, SciPy, and Matplotlib communities. 


